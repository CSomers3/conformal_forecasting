{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "324b6744-7b43-4465-bde6-d47e573a3198",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "324b6744-7b43-4465-bde6-d47e573a3198",
        "outputId": "ed901739-f585-4b51-cc15-a6c0fded520e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded sequence data from Zarr cache: data_cache.zarr\n",
            "Creating tabular features for tree-based models...\n",
            "Tabular feature creation complete. Shape: (8706, 14)\n",
            "Running on device: cuda\n",
            "\n",
            "==================================================\n",
            "Running model: GCN_GRU\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rForecasting with gcn_gru:   0%|          | 0/855 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Retraining gcn_gru at Timestamp: 2022-06-01 00:00:00+00:00\n",
            "Training NN model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rForecasting with gcn_gru:   0%|          | 1/855 [02:12<31:26:23, 132.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Retraining gcn_gru at Timestamp: 2022-06-08 00:00:00+00:00\n",
            "Training NN model...\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Main forecasting benchmark runner.\n",
        "\n",
        "This script orchestrates the entire pipeline:\n",
        "1. Loads and preprocesses data (using Zarr for caching).\n",
        "2. Sets up the graph structure for the GCN model.\n",
        "3. Iterates through each model defined in the config.\n",
        "4. Runs a robust, non-overlapping (stacked) forecast evaluation with weekly retraining.\n",
        "5. Calculates performance metrics (MAE, RMSE) for each hour in the forecast horizon.\n",
        "6. Saves the final forecasts and a summary of the results.\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from tqdm import tqdm\n",
        "\n",
        "from config import CONFIG\n",
        "from data_handler import create_tabular_features, load_or_create_zarr_cache\n",
        "from models import (ARIMABaseline, ARIMAModelWrapper, GCN_GRU, NNModelWrapper,\n",
        "                    QuantileRegressionWrapper)\n",
        "from utils import build_adjacency_from_coords, normalize_adj\n",
        "\n",
        "\n",
        "def run_benchmark():\n",
        "    \"\"\"Main forecasting benchmark runner.\"\"\"\n",
        "    # --- 1. Load Data and Config ---\n",
        "    conf = CONFIG\n",
        "    all_data_seq, timestamps = load_or_create_zarr_cache(\n",
        "        conf[\"data\"][\"source_path\"], conf[\"data\"][\"zarr_path\"]\n",
        "    )\n",
        "    X_tab, y_tab = create_tabular_features(\n",
        "        all_data_seq, timestamps, conf[\"data\"][\"horizon\"]\n",
        "    )\n",
        "\n",
        "    device = conf[\"run\"][\"device\"]\n",
        "    print(f\"Running on device: {device}\")\n",
        "\n",
        "    # --- 2. Setup Experiment ---\n",
        "    n_turbines = all_data_seq.shape[1]\n",
        "    coords = np.array([v for _, v in sorted(conf[\"graph\"][\"coords\"].items())])\n",
        "    A = build_adjacency_from_coords(coords, k=conf[\"graph\"][\"k_neighbors\"])\n",
        "    A_hat = normalize_adj(A)\n",
        "    horizon = conf[\"data\"][\"horizon\"]\n",
        "\n",
        "    test_start_date = pd.to_datetime(conf[\"evaluation\"][\"test_start_date\"], utc=True)\n",
        "    test_start_idx = timestamps.get_loc(test_start_date)\n",
        "\n",
        "    # --- 3. Run Models ---\n",
        "    results = {}\n",
        "    all_model_preds, all_model_lower, all_model_upper = {}, {}, {}\n",
        "    final_trues = None\n",
        "\n",
        "    for model_name, model_config in conf[\"models\"].items():\n",
        "        print(\"\\n\" + \"=\" * 50 + f\"\\nRunning model: {model_name.upper()}\\n\" + \"=\" * 50)\n",
        "\n",
        "        all_preds, all_trues, all_lower, all_upper = [], [], [], []\n",
        "        forecast_timestamps = []\n",
        "        last_retrain_idx = -np.inf # Ensure training happens on the first step\n",
        "\n",
        "        wrapper_class = globals()[model_config[\"wrapper\"]]\n",
        "        model_instance = wrapper_class(\n",
        "            data_params=conf[\"data\"], n_turbines=n_turbines, device=device, **model_config\n",
        "        )\n",
        "\n",
        "        test_range = range(test_start_idx, len(timestamps) - horizon, horizon)\n",
        "        for forecast_start_idx in tqdm(test_range, desc=f\"Forecasting with {model_name}\"):\n",
        "\n",
        "            # Retraining logic\n",
        "            if forecast_start_idx >= last_retrain_idx + conf[\"evaluation\"][\"retrain_every_hours\"]:\n",
        "                print(f\"\\nRetraining {model_name} at Timestamp: {timestamps[forecast_start_idx]}\")\n",
        "                last_retrain_idx = forecast_start_idx\n",
        "                train_end_idx = forecast_start_idx\n",
        "\n",
        "                # **FIX**: Use .get() for robust access to prevent KeyError\n",
        "                rolling_window = model_config[\"training\"].get(\"rolling_window_size\", len(timestamps))\n",
        "                train_start_idx = max(0, train_end_idx - rolling_window)\n",
        "\n",
        "                if model_config[\"wrapper\"] == \"QuantileRegressionWrapper\":\n",
        "                    train_mask = (X_tab.index >= timestamps[train_start_idx]) & (X_tab.index < timestamps[train_end_idx])\n",
        "                    model_instance.train(X_tab[train_mask], y_tab[train_mask])\n",
        "                else:\n",
        "                    # Ensure training indices are valid\n",
        "                    train_indices = list(range(train_start_idx, max(train_start_idx, train_end_idx - conf[\"data\"][\"lookback\"] - horizon)))\n",
        "                    model_instance.train(all_data_seq, train_indices=train_indices, A_hat=A_hat)\n",
        "\n",
        "            # Prediction logic\n",
        "            if model_config[\"wrapper\"] == \"QuantileRegressionWrapper\":\n",
        "                # Ensure the feature row exists before trying to predict\n",
        "                if timestamps[forecast_start_idx - 1] in X_tab.index:\n",
        "                    X_test = X_tab.loc[[timestamps[forecast_start_idx - 1]]]\n",
        "                    pred = model_instance.predict(X_test)\n",
        "                else: # Skip if no features available (e.g., due to dropna)\n",
        "                    continue\n",
        "            else:\n",
        "                lookback_start = forecast_start_idx - conf[\"data\"][\"lookback\"]\n",
        "                seq_window = all_data_seq[lookback_start:forecast_start_idx]\n",
        "                # **FIX**: Pass the adjacency matrix `A_hat` to the predict method\n",
        "                pred = model_instance.predict(seq_window, A_hat=A_hat)\n",
        "\n",
        "            # Store results\n",
        "            true_slice = slice(forecast_start_idx, forecast_start_idx + horizon)\n",
        "            true_values = all_data_seq[true_slice, :, 0]\n",
        "            all_trues.append(true_values.sum(axis=1))\n",
        "            forecast_timestamps.extend(timestamps[true_slice])\n",
        "\n",
        "            if model_config[\"wrapper\"] == \"QuantileRegressionWrapper\":\n",
        "                all_preds.append(pred[0.5][0])\n",
        "                all_lower.append(pred[0.05][0])\n",
        "                all_upper.append(pred[0.95][0])\n",
        "            else:\n",
        "                all_preds.append(pred.sum(axis=1))\n",
        "\n",
        "        # --- 4. Evaluate and Store Model Results ---\n",
        "        farm_preds_np = np.array(all_preds)\n",
        "        farm_trues_np = np.array(all_trues)\n",
        "\n",
        "        all_model_preds[model_name] = farm_preds_np\n",
        "        if final_trues is None: final_trues = farm_trues_np\n",
        "\n",
        "        if all_lower:\n",
        "            all_model_lower[model_name] = np.array(all_lower)\n",
        "            all_model_upper[model_name] = np.array(all_upper)\n",
        "\n",
        "        metrics_per_horizon = {}\n",
        "        for h in range(horizon):\n",
        "            mae = mean_absolute_error(farm_trues_np[:, h], farm_preds_np[:, h])\n",
        "            rmse = np.sqrt(mean_squared_error(farm_trues_np[:, h], farm_preds_np[:, h]))\n",
        "            metrics_per_horizon[f\"h{h+1}_mae\"] = mae\n",
        "            metrics_per_horizon[f\"h{h+1}_rmse\"] = rmse\n",
        "        results[model_name] = metrics_per_horizon\n",
        "\n",
        "    # --- 5. Assemble Final Stacked DataFrame ---\n",
        "    # **FIX**: More robust and clear way to build the final results DataFrame\n",
        "    final_index = pd.to_datetime(forecast_timestamps).unique()\n",
        "    final_df_list = []\n",
        "\n",
        "    # Ensure actuals are added only once and correctly indexed\n",
        "    actuals_flat = final_trues.reshape(-1)\n",
        "    actuals_df = pd.DataFrame({'actual': actuals_flat}, index=final_index[:len(actuals_flat)])\n",
        "    final_df_list.append(actuals_df)\n",
        "\n",
        "    for model_name, preds in all_model_preds.items():\n",
        "        preds_flat = preds.reshape(-1)\n",
        "        pred_df = pd.DataFrame({model_name: preds_flat}, index=final_index[:len(preds_flat)])\n",
        "        final_df_list.append(pred_df)\n",
        "\n",
        "    for model_name, lower in all_model_lower.items():\n",
        "        lower_flat = lower.reshape(-1)\n",
        "        df = pd.DataFrame({f\"{model_name}_lower\": lower_flat}, index=final_index[:len(lower_flat)])\n",
        "        final_df_list.append(df)\n",
        "    for model_name, upper in all_model_upper.items():\n",
        "        upper_flat = upper.reshape(-1)\n",
        "        df = pd.DataFrame({f\"{model_name}_upper\": upper_flat}, index=final_index[:len(upper_flat)])\n",
        "        final_df_list.append(df)\n",
        "\n",
        "    farm_forecasts_df = pd.concat(final_df_list, axis=1)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\nFINAL RESULTS SUMMARY\\n\" + \"=\"*50)\n",
        "    summary_df = pd.DataFrame(results).T\n",
        "    print(summary_df.to_string(float_format=\"%.2f\"))\n",
        "\n",
        "    return summary_df, farm_forecasts_df\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # This block will only run when the script is executed directly\n",
        "    final_results, final_forecasts = run_benchmark()\n",
        "    final_forecasts.to_pickle(\"final_forecasts.pkl\")\n",
        "    print(\"\\nForecasts saved to 'final_forecasts.pkl'\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_forecasts"
      ],
      "metadata": {
        "id": "L5pH277kKADO"
      },
      "id": "L5pH277kKADO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-m4_ahQcRMxD"
      },
      "id": "-m4_ahQcRMxD",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}